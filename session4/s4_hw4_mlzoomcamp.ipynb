{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Homework 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2021-10-01 16:39:54--  https://raw.githubusercontent.com/alexeygrigorev/mlbookcamp-code/master/chapter-06-trees/CreditScoring.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 182489 (178K) [text/plain]\n",
      "Saving to: 'CreditScoring.csv.7'\n",
      "\n",
      "     0K .......... .......... .......... .......... .......... 28% 1.50M 0s\n",
      "    50K .......... .......... .......... .......... .......... 56% 23.1M 0s\n",
      "   100K .......... .......... .......... .......... .......... 84% 32.5M 0s\n",
      "   150K .......... .......... ........                        100% 20.8M=0.04s\n",
      "\n",
      "2021-10-01 16:39:54 (4.65 MB/s) - 'CreditScoring.csv.7' saved [182489/182489]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/alexeygrigorev/mlbookcamp-code/master/chapter-06-trees/CreditScoring.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Preparation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('CreditScoring.csv')\n",
    "\n",
    "df.columns = df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_values = {\n",
    "    1: 'ok',\n",
    "    2: 'default',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.status = df.status.map(status_values)\n",
    "\n",
    "\n",
    "home_values = {\n",
    "    1: 'rent',\n",
    "    2: 'owner',\n",
    "    3: 'private',\n",
    "    4: 'ignore',\n",
    "    5: 'parents',\n",
    "    6: 'other',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.home = df.home.map(home_values)\n",
    "\n",
    "marital_values = {\n",
    "    1: 'single',\n",
    "    2: 'married',\n",
    "    3: 'widow',\n",
    "    4: 'separated',\n",
    "    5: 'divorced',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.marital = df.marital.map(marital_values)\n",
    "\n",
    "records_values = {\n",
    "    1: 'no',\n",
    "    2: 'yes',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.records = df.records.map(records_values)\n",
    "\n",
    "job_values = {\n",
    "    1: 'fixed',\n",
    "    2: 'partime',\n",
    "    3: 'freelance',\n",
    "    4: 'others',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.job = df.job.map(job_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Prepare the numerical variables:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for c in ['income', 'assets', 'debt']:\n",
    "    df[c] = df[c].replace(to_replace=99999999, value=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Remove clients with unknown default status\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.status != 'unk'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Create the target variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['default'] = (df.status == 'default').astype(int)\n",
    "del df['status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seniority</th>\n",
       "      <th>home</th>\n",
       "      <th>time</th>\n",
       "      <th>age</th>\n",
       "      <th>marital</th>\n",
       "      <th>records</th>\n",
       "      <th>job</th>\n",
       "      <th>expenses</th>\n",
       "      <th>income</th>\n",
       "      <th>assets</th>\n",
       "      <th>debt</th>\n",
       "      <th>amount</th>\n",
       "      <th>price</th>\n",
       "      <th>default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>rent</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>married</td>\n",
       "      <td>no</td>\n",
       "      <td>freelance</td>\n",
       "      <td>73</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>800</td>\n",
       "      <td>846</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>rent</td>\n",
       "      <td>60</td>\n",
       "      <td>58</td>\n",
       "      <td>widow</td>\n",
       "      <td>no</td>\n",
       "      <td>fixed</td>\n",
       "      <td>48</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1658</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>owner</td>\n",
       "      <td>36</td>\n",
       "      <td>46</td>\n",
       "      <td>married</td>\n",
       "      <td>yes</td>\n",
       "      <td>freelance</td>\n",
       "      <td>90</td>\n",
       "      <td>200</td>\n",
       "      <td>3000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>2985</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>rent</td>\n",
       "      <td>60</td>\n",
       "      <td>24</td>\n",
       "      <td>single</td>\n",
       "      <td>no</td>\n",
       "      <td>fixed</td>\n",
       "      <td>63</td>\n",
       "      <td>182</td>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "      <td>900</td>\n",
       "      <td>1325</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>rent</td>\n",
       "      <td>36</td>\n",
       "      <td>26</td>\n",
       "      <td>single</td>\n",
       "      <td>no</td>\n",
       "      <td>fixed</td>\n",
       "      <td>46</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>310</td>\n",
       "      <td>910</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4449</th>\n",
       "      <td>1</td>\n",
       "      <td>rent</td>\n",
       "      <td>60</td>\n",
       "      <td>39</td>\n",
       "      <td>married</td>\n",
       "      <td>no</td>\n",
       "      <td>fixed</td>\n",
       "      <td>69</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>900</td>\n",
       "      <td>1020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4450</th>\n",
       "      <td>22</td>\n",
       "      <td>owner</td>\n",
       "      <td>60</td>\n",
       "      <td>46</td>\n",
       "      <td>married</td>\n",
       "      <td>no</td>\n",
       "      <td>fixed</td>\n",
       "      <td>60</td>\n",
       "      <td>75</td>\n",
       "      <td>3000</td>\n",
       "      <td>600</td>\n",
       "      <td>950</td>\n",
       "      <td>1263</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4451</th>\n",
       "      <td>0</td>\n",
       "      <td>owner</td>\n",
       "      <td>24</td>\n",
       "      <td>37</td>\n",
       "      <td>married</td>\n",
       "      <td>no</td>\n",
       "      <td>partime</td>\n",
       "      <td>60</td>\n",
       "      <td>90</td>\n",
       "      <td>3500</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>963</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4452</th>\n",
       "      <td>0</td>\n",
       "      <td>rent</td>\n",
       "      <td>48</td>\n",
       "      <td>23</td>\n",
       "      <td>single</td>\n",
       "      <td>no</td>\n",
       "      <td>freelance</td>\n",
       "      <td>49</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>550</td>\n",
       "      <td>550</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4453</th>\n",
       "      <td>5</td>\n",
       "      <td>owner</td>\n",
       "      <td>60</td>\n",
       "      <td>32</td>\n",
       "      <td>married</td>\n",
       "      <td>no</td>\n",
       "      <td>freelance</td>\n",
       "      <td>60</td>\n",
       "      <td>140</td>\n",
       "      <td>4000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1350</td>\n",
       "      <td>1650</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4454 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      seniority   home  time  age  marital records        job  expenses  \\\n",
       "0             9   rent    60   30  married      no  freelance        73   \n",
       "1            17   rent    60   58    widow      no      fixed        48   \n",
       "2            10  owner    36   46  married     yes  freelance        90   \n",
       "3             0   rent    60   24   single      no      fixed        63   \n",
       "4             0   rent    36   26   single      no      fixed        46   \n",
       "...         ...    ...   ...  ...      ...     ...        ...       ...   \n",
       "4449          1   rent    60   39  married      no      fixed        69   \n",
       "4450         22  owner    60   46  married      no      fixed        60   \n",
       "4451          0  owner    24   37  married      no    partime        60   \n",
       "4452          0   rent    48   23   single      no  freelance        49   \n",
       "4453          5  owner    60   32  married      no  freelance        60   \n",
       "\n",
       "      income  assets  debt  amount  price  default  \n",
       "0        129       0     0     800    846        0  \n",
       "1        131       0     0    1000   1658        0  \n",
       "2        200    3000     0    2000   2985        1  \n",
       "3        182    2500     0     900   1325        0  \n",
       "4        107       0     0     310    910        0  \n",
       "...      ...     ...   ...     ...    ...      ...  \n",
       "4449      92       0     0     900   1020        1  \n",
       "4450      75    3000   600     950   1263        0  \n",
       "4451      90    3500     0     500    963        1  \n",
       "4452     140       0     0     550    550        0  \n",
       "4453     140    4000  1000    1350   1650        0  \n",
       "\n",
       "[4454 rows x 14 columns]"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.dtypes.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Your code\n",
    "\n",
    "What are the categorical variables? What are the numerical?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = []\n",
    "numerical = []\n",
    "for i in range(len(df.dtypes.index)):\n",
    "\n",
    "    if df.dtypes.values[i] == object:\n",
    "        categorical.append(df.dtypes.index[i])\n",
    "    else:\n",
    "        numerical.append(df.dtypes.index[i])\n",
    "        \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The categorical varaibles are : ['home', 'marital', 'records', 'job']'\n",
      "\n",
      "'The numerical variables are : ['seniority', 'time', 'age', 'expenses', 'income', 'assets', 'debt', 'amount', 'price', 'default'] \n"
     ]
    }
   ],
   "source": [
    "print(\"The categorical varaibles are : %s'\\n\\n'The numerical variables are : %s \" % (categorical,numerical))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Split the data into 3 parts: train/validation/test with 60%/20%/20% distribution. Use train_test_split funciton for that with random_state=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_train,df_test = train_test_split(df,test_size = 0.2,random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train,df_val = train_test_split(df_full_train,test_size=0.25,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2672, 891, 891)"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train),len(df_val),len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resetindex\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "#target_variables\n",
    "y_train = df_train.default.values\n",
    "y_val = df_val.default.values\n",
    "y_test = df_test.default.values\n",
    "\n",
    "#delete_target_values_from_dataframe\n",
    "del df_train['default']\n",
    "del df_val['default']\n",
    "del df_test['default']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 \n",
    "\n",
    "ROC AUC could also be used to evaluate feature importance of numerical variables.\n",
    "\n",
    "Let's do that\n",
    "\n",
    "    For each numerical variable, use it as score and compute AUC with the default variable\n",
    "    Use the training dataset for that\n",
    "\n",
    "If your AUC is < 0.5, invert this variable by putting \"-\" in front\n",
    "\n",
    "(e.g. -df_train['expenses'])\n",
    "\n",
    "AUC can go below 0.5 if the variable is negatively correlated with the target varialble. You can change the direction of the correlation by negating this variable - then negative correlation becomes positive.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7093778624491943"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_seniority = roc_auc_score(y_train,-df_train['seniority'])\n",
    "auc_seniority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5608662489595051"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_time = roc_auc_score(y_train,df_train['time'])\n",
    "auc_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.682006666132633"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_income = roc_auc_score(y_train,-df_train['income'])\n",
    "auc_income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5047829675783548"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_debt = roc_auc_score(y_train,-df_train['debt'])\n",
    "auc_debt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Which numerical variable (among the following 4) has the highest AUC?\n",
    "\n",
    "    seniority\n",
    "    time\n",
    "    income\n",
    "    debt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest AUC is : 0.709\n",
      "\n",
      "The numerical variable with highest AUC is : seniority\n"
     ]
    }
   ],
   "source": [
    "print(\"The highest AUC is : %s\\n\\nThe numerical variable with highest AUC is : %s\" % (round(max(auc_seniority,auc_time,auc_income,auc_debt),3),\"seniority\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Training the model\n",
    "\n",
    "From now on, use these columns only:\n",
    "\n",
    "['seniority', 'income', 'assets', 'records', 'job', 'home']\n",
    "\n",
    "Apply one-hot-encoding using DictVectorizer and train the logistic regression with these parameters:\n",
    "\n",
    "LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot-encoding with sklearn\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "#declaring numerical variables\n",
    "numerical = ['seniority', 'income', 'assets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "#declaring categorical variables\n",
    "\n",
    "categorical = ['home', 'records', 'job']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing the training set in a dictionary\n",
    "train_dicts = df_train[categorical + numerical].to_dict(orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the variable for one hot encoding method function DictVectorizer\n",
    "dv = DictVectorizer(sparse = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling the moethod function to ohe the training dictionary\n",
    "dv.fit(train_dicts)\n",
    "\n",
    "#training data set is transformed with ohe\n",
    "X_train = dv.transform(train_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['assets',\n",
       " 'home=ignore',\n",
       " 'home=other',\n",
       " 'home=owner',\n",
       " 'home=parents',\n",
       " 'home=private',\n",
       " 'home=rent',\n",
       " 'home=unk',\n",
       " 'income',\n",
       " 'job=fixed',\n",
       " 'job=freelance',\n",
       " 'job=others',\n",
       " 'job=partime',\n",
       " 'job=unk',\n",
       " 'records=no',\n",
       " 'records=yes',\n",
       " 'seniority']"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0e+00, 0.0e+00, 0.0e+00, ..., 1.0e+00, 0.0e+00, 1.2e+01],\n",
       "       [0.0e+00, 0.0e+00, 1.0e+00, ..., 1.0e+00, 0.0e+00, 4.0e+00],\n",
       "       [6.0e+03, 0.0e+00, 0.0e+00, ..., 1.0e+00, 0.0e+00, 0.0e+00],\n",
       "       ...,\n",
       "       [0.0e+00, 0.0e+00, 0.0e+00, ..., 0.0e+00, 1.0e+00, 9.0e+00],\n",
       "       [3.0e+03, 0.0e+00, 0.0e+00, ..., 1.0e+00, 0.0e+00, 0.0e+00],\n",
       "       [0.0e+00, 0.0e+00, 0.0e+00, ..., 1.0e+00, 0.0e+00, 8.0e+00]])"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing the valdiation set in a dictionary\n",
    "\n",
    "val_dicts = df_val[categorical+numerical].to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation data set is transformed with ohe\n",
    "X_val = dv.transform(val_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model function\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, solver='liblinear')"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We fit the model with X_train,y_train\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75439854])"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bias_term\n",
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.28850078e-05,  3.57366686e-02,  4.93587198e-01,\n",
       "        -3.84688367e-01, -1.89351066e-01,  3.00655283e-01,\n",
       "         4.88847620e-01,  9.61120814e-03, -6.93659513e-03,\n",
       "        -3.49659459e-01,  1.03746104e-01,  7.70714470e-02,\n",
       "         9.14958825e-01,  8.28162721e-03, -5.05448841e-01,\n",
       "         1.25984739e+00, -8.12030164e-02]])"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#weights_terms\n",
    "model.coef_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The target feature is predicted with valdiation set\n",
    "y_pred = model.predict_proba(X_val)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr,tpr,thresholds= roc_curve(y_val,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8120879813449298"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc(fpr,tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Question 2\n",
    "\n",
    "What's the AUC of this model on the validation dataset? (round to 3 digits)\n",
    "\n",
    "    0.512\n",
    "    0.612\n",
    "    0.712\n",
    "    0.812\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC of this model on the validation dataset : 0.812\n"
     ]
    }
   ],
   "source": [
    "print(\"AUC of this model on the validation dataset : %s\" % round(auc(fpr,tpr),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Question 3\n",
    "\n",
    "Now let's compute precision and recall for our model.\n",
    "\n",
    "    Evaluate the model on all thresholds from 0.0 to 1.0 with step 0.01\n",
    "    For each threshold, compute precision and recall\n",
    "    Plot them\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate precision and recall iterated through different thresholds\n",
    "\n",
    "def prec_rec(y_val,y_pred):\n",
    "    \n",
    "    #Thresholds variable is created\n",
    "    thresholds = np.linspace(0,1,101)\n",
    "    \n",
    "    threshold_precision_recall = []\n",
    "    \n",
    "    precision_values = []\n",
    "    \n",
    "    recall_values = []\n",
    "    \n",
    "    for t in thresholds:\n",
    "        #Actual outcome\n",
    "        actual_positive = (y_val ==1)\n",
    "        actual_negative = (y_val ==0)\n",
    "        \n",
    "        #Predicted outcome  \n",
    "        predict_positve = (y_pred>=t)\n",
    "        predict_negative = (y_pred<t)\n",
    "        \n",
    "        #TP,FP,TN,FN are calculated\n",
    "        true_positive = (predict_positve & actual_positive).sum()\n",
    "        false_positive =(predict_positve & actual_negative).sum()\n",
    "        \n",
    "        true_negative = (predict_negative & actual_negative).sum()\n",
    "        false_negative = (predict_negative & actual_positive).sum()\n",
    "        \n",
    "        if (true_positive + false_positive)==0 or (true_positive+false_negative) ==0 :\n",
    "            print(\"Zero Division Error for t = %s\" % t)\n",
    "        else:\n",
    "            #Precision is calculated\n",
    "            precision = true_positive/(true_positive + false_positive)\n",
    "            \n",
    "            #Recall is calculated\n",
    "            recall = true_positive/(true_positive+false_negative)\n",
    "\n",
    "            threshold_precision_recall.append((t,precision,recall))\n",
    "            precision_values.append(precision)\n",
    "            recall_values.append(recall)\n",
    "            \n",
    "    return threshold_precision_recall,precision_values,recall_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero Division Error for t = 0.9400000000000001\n",
      "Zero Division Error for t = 0.9500000000000001\n",
      "Zero Division Error for t = 0.96\n",
      "Zero Division Error for t = 0.97\n",
      "Zero Division Error for t = 0.98\n",
      "Zero Division Error for t = 0.99\n",
      "Zero Division Error for t = 1.0\n"
     ]
    }
   ],
   "source": [
    "#The thresholds and the corresponding Precision and Recall values are gathered as input from the function prec_rec()\n",
    "threshold_precision_recall,precision_values,recall_values = prec_rec(y_val,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 0.2760942760942761, 1.0),\n",
       " (0.01, 0.2792281498297389, 1.0),\n",
       " (0.02, 0.2847141190198366, 0.991869918699187),\n",
       " (0.03, 0.2898203592814371, 0.983739837398374),\n",
       " (0.04, 0.30062111801242236, 0.983739837398374),\n",
       " (0.05, 0.30407124681933845, 0.9715447154471545),\n",
       " (0.06, 0.31241830065359477, 0.9715447154471545),\n",
       " (0.07, 0.3203230148048452, 0.967479674796748),\n",
       " (0.08, 0.3296398891966759, 0.967479674796748),\n",
       " (0.09, 0.33905579399141633, 0.9634146341463414),\n",
       " (0.1, 0.34558823529411764, 0.9552845528455285),\n",
       " (0.11, 0.3531202435312024, 0.943089430894309),\n",
       " (0.12, 0.3656597774244833, 0.9349593495934959),\n",
       " (0.13, 0.37976782752902155, 0.9308943089430894),\n",
       " (0.14, 0.38813559322033897, 0.9308943089430894),\n",
       " (0.15, 0.40353982300884955, 0.926829268292683),\n",
       " (0.16, 0.4106813996316759, 0.9065040650406504),\n",
       " (0.17, 0.41825095057034223, 0.8943089430894309),\n",
       " (0.18, 0.427734375, 0.8902439024390244),\n",
       " (0.19, 0.43887775551102204, 0.8902439024390244),\n",
       " (0.2, 0.4460580912863071, 0.8739837398373984),\n",
       " (0.21, 0.4557235421166307, 0.8577235772357723),\n",
       " (0.22, 0.4678492239467849, 0.8577235772357723),\n",
       " (0.23, 0.47380410022779046, 0.8455284552845529),\n",
       " (0.24, 0.4834123222748815, 0.8292682926829268),\n",
       " (0.25, 0.49144254278728605, 0.8170731707317073),\n",
       " (0.26, 0.49373433583959897, 0.8008130081300813),\n",
       " (0.27, 0.5012987012987012, 0.7845528455284553),\n",
       " (0.28, 0.5120643431635389, 0.7764227642276422),\n",
       " (0.29, 0.5220994475138122, 0.7682926829268293),\n",
       " (0.3, 0.5358166189111748, 0.7601626016260162),\n",
       " (0.31, 0.5411764705882353, 0.7479674796747967),\n",
       " (0.32, 0.5468277945619335, 0.7357723577235772),\n",
       " (0.33, 0.55, 0.7154471544715447),\n",
       " (0.34, 0.5602605863192183, 0.6991869918699187),\n",
       " (0.35000000000000003, 0.5637583892617449, 0.6829268292682927),\n",
       " (0.36, 0.5694444444444444, 0.6666666666666666),\n",
       " (0.37, 0.5770609318996416, 0.6544715447154471),\n",
       " (0.38, 0.5783582089552238, 0.6300813008130082),\n",
       " (0.39, 0.58203125, 0.6056910569105691),\n",
       " (0.4, 0.5833333333333334, 0.5691056910569106),\n",
       " (0.41000000000000003, 0.5938864628820961, 0.5528455284552846),\n",
       " (0.42, 0.5964125560538116, 0.540650406504065),\n",
       " (0.43, 0.5944700460829493, 0.524390243902439),\n",
       " (0.44, 0.6076555023923444, 0.516260162601626),\n",
       " (0.45, 0.6078431372549019, 0.5040650406504065),\n",
       " (0.46, 0.6212121212121212, 0.5),\n",
       " (0.47000000000000003, 0.625, 0.4878048780487805),\n",
       " (0.48, 0.6310160427807486, 0.4796747967479675),\n",
       " (0.49, 0.6388888888888888, 0.46747967479674796),\n",
       " (0.5, 0.6404494382022472, 0.4634146341463415),\n",
       " (0.51, 0.6470588235294118, 0.44715447154471544),\n",
       " (0.52, 0.6441717791411042, 0.4268292682926829),\n",
       " (0.53, 0.65, 0.42276422764227645),\n",
       " (0.54, 0.6666666666666666, 0.4065040650406504),\n",
       " (0.55, 0.676056338028169, 0.3902439024390244),\n",
       " (0.56, 0.674074074074074, 0.3699186991869919),\n",
       " (0.5700000000000001, 0.6666666666666666, 0.34146341463414637),\n",
       " (0.58, 0.6694214876033058, 0.32926829268292684),\n",
       " (0.59, 0.6666666666666666, 0.3252032520325203),\n",
       " (0.6, 0.6724137931034483, 0.3170731707317073),\n",
       " (0.61, 0.6759259259259259, 0.2967479674796748),\n",
       " (0.62, 0.693069306930693, 0.2845528455284553),\n",
       " (0.63, 0.7083333333333334, 0.2764227642276423),\n",
       " (0.64, 0.7126436781609196, 0.25203252032520324),\n",
       " (0.65, 0.7283950617283951, 0.23983739837398374),\n",
       " (0.66, 0.7066666666666667, 0.21544715447154472),\n",
       " (0.67, 0.7162162162162162, 0.21544715447154472),\n",
       " (0.68, 0.726027397260274, 0.21544715447154472),\n",
       " (0.6900000000000001, 0.7272727272727273, 0.1951219512195122),\n",
       " (0.7000000000000001, 0.6981132075471698, 0.15040650406504066),\n",
       " (0.71, 0.7058823529411765, 0.14634146341463414),\n",
       " (0.72, 0.7021276595744681, 0.13414634146341464),\n",
       " (0.73, 0.7021276595744681, 0.13414634146341464),\n",
       " (0.74, 0.6888888888888889, 0.12601626016260162),\n",
       " (0.75, 0.7, 0.11382113821138211),\n",
       " (0.76, 0.7, 0.11382113821138211),\n",
       " (0.77, 0.7428571428571429, 0.10569105691056911),\n",
       " (0.78, 0.71875, 0.09349593495934959),\n",
       " (0.79, 0.7333333333333333, 0.08943089430894309),\n",
       " (0.8, 0.8076923076923077, 0.08536585365853659),\n",
       " (0.81, 0.8076923076923077, 0.08536585365853659),\n",
       " (0.8200000000000001, 0.8333333333333334, 0.08130081300813008),\n",
       " (0.8300000000000001, 0.8571428571428571, 0.07317073170731707),\n",
       " (0.84, 0.8125, 0.052845528455284556),\n",
       " (0.85, 0.7857142857142857, 0.044715447154471545),\n",
       " (0.86, 0.7857142857142857, 0.044715447154471545),\n",
       " (0.87, 0.75, 0.036585365853658534),\n",
       " (0.88, 0.7272727272727273, 0.032520325203252036),\n",
       " (0.89, 0.7777777777777778, 0.028455284552845527),\n",
       " (0.9, 0.75, 0.024390243902439025),\n",
       " (0.91, 0.8, 0.016260162601626018),\n",
       " (0.92, 0.8, 0.016260162601626018),\n",
       " (0.93, 1.0, 0.008130081300813009)]"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold_precision_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2760942760942761,\n",
       " 0.2792281498297389,\n",
       " 0.2847141190198366,\n",
       " 0.2898203592814371,\n",
       " 0.30062111801242236,\n",
       " 0.30407124681933845,\n",
       " 0.31241830065359477,\n",
       " 0.3203230148048452,\n",
       " 0.3296398891966759,\n",
       " 0.33905579399141633,\n",
       " 0.34558823529411764,\n",
       " 0.3531202435312024,\n",
       " 0.3656597774244833,\n",
       " 0.37976782752902155,\n",
       " 0.38813559322033897,\n",
       " 0.40353982300884955,\n",
       " 0.4106813996316759,\n",
       " 0.41825095057034223,\n",
       " 0.427734375,\n",
       " 0.43887775551102204,\n",
       " 0.4460580912863071,\n",
       " 0.4557235421166307,\n",
       " 0.4678492239467849,\n",
       " 0.47380410022779046,\n",
       " 0.4834123222748815,\n",
       " 0.49144254278728605,\n",
       " 0.49373433583959897,\n",
       " 0.5012987012987012,\n",
       " 0.5120643431635389,\n",
       " 0.5220994475138122,\n",
       " 0.5358166189111748,\n",
       " 0.5411764705882353,\n",
       " 0.5468277945619335,\n",
       " 0.55,\n",
       " 0.5602605863192183,\n",
       " 0.5637583892617449,\n",
       " 0.5694444444444444,\n",
       " 0.5770609318996416,\n",
       " 0.5783582089552238,\n",
       " 0.58203125,\n",
       " 0.5833333333333334,\n",
       " 0.5938864628820961,\n",
       " 0.5964125560538116,\n",
       " 0.5944700460829493,\n",
       " 0.6076555023923444,\n",
       " 0.6078431372549019,\n",
       " 0.6212121212121212,\n",
       " 0.625,\n",
       " 0.6310160427807486,\n",
       " 0.6388888888888888,\n",
       " 0.6404494382022472,\n",
       " 0.6470588235294118,\n",
       " 0.6441717791411042,\n",
       " 0.65,\n",
       " 0.6666666666666666,\n",
       " 0.676056338028169,\n",
       " 0.674074074074074,\n",
       " 0.6666666666666666,\n",
       " 0.6694214876033058,\n",
       " 0.6666666666666666,\n",
       " 0.6724137931034483,\n",
       " 0.6759259259259259,\n",
       " 0.693069306930693,\n",
       " 0.7083333333333334,\n",
       " 0.7126436781609196,\n",
       " 0.7283950617283951,\n",
       " 0.7066666666666667,\n",
       " 0.7162162162162162,\n",
       " 0.726027397260274,\n",
       " 0.7272727272727273,\n",
       " 0.6981132075471698,\n",
       " 0.7058823529411765,\n",
       " 0.7021276595744681,\n",
       " 0.7021276595744681,\n",
       " 0.6888888888888889,\n",
       " 0.7,\n",
       " 0.7,\n",
       " 0.7428571428571429,\n",
       " 0.71875,\n",
       " 0.7333333333333333,\n",
       " 0.8076923076923077,\n",
       " 0.8076923076923077,\n",
       " 0.8333333333333334,\n",
       " 0.8571428571428571,\n",
       " 0.8125,\n",
       " 0.7857142857142857,\n",
       " 0.7857142857142857,\n",
       " 0.75,\n",
       " 0.7272727272727273,\n",
       " 0.7777777777777778,\n",
       " 0.75,\n",
       " 0.8,\n",
       " 0.8,\n",
       " 1.0]"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Precision Values\n",
    "precision_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 1.0,\n",
       " 0.991869918699187,\n",
       " 0.983739837398374,\n",
       " 0.983739837398374,\n",
       " 0.9715447154471545,\n",
       " 0.9715447154471545,\n",
       " 0.967479674796748,\n",
       " 0.967479674796748,\n",
       " 0.9634146341463414,\n",
       " 0.9552845528455285,\n",
       " 0.943089430894309,\n",
       " 0.9349593495934959,\n",
       " 0.9308943089430894,\n",
       " 0.9308943089430894,\n",
       " 0.926829268292683,\n",
       " 0.9065040650406504,\n",
       " 0.8943089430894309,\n",
       " 0.8902439024390244,\n",
       " 0.8902439024390244,\n",
       " 0.8739837398373984,\n",
       " 0.8577235772357723,\n",
       " 0.8577235772357723,\n",
       " 0.8455284552845529,\n",
       " 0.8292682926829268,\n",
       " 0.8170731707317073,\n",
       " 0.8008130081300813,\n",
       " 0.7845528455284553,\n",
       " 0.7764227642276422,\n",
       " 0.7682926829268293,\n",
       " 0.7601626016260162,\n",
       " 0.7479674796747967,\n",
       " 0.7357723577235772,\n",
       " 0.7154471544715447,\n",
       " 0.6991869918699187,\n",
       " 0.6829268292682927,\n",
       " 0.6666666666666666,\n",
       " 0.6544715447154471,\n",
       " 0.6300813008130082,\n",
       " 0.6056910569105691,\n",
       " 0.5691056910569106,\n",
       " 0.5528455284552846,\n",
       " 0.540650406504065,\n",
       " 0.524390243902439,\n",
       " 0.516260162601626,\n",
       " 0.5040650406504065,\n",
       " 0.5,\n",
       " 0.4878048780487805,\n",
       " 0.4796747967479675,\n",
       " 0.46747967479674796,\n",
       " 0.4634146341463415,\n",
       " 0.44715447154471544,\n",
       " 0.4268292682926829,\n",
       " 0.42276422764227645,\n",
       " 0.4065040650406504,\n",
       " 0.3902439024390244,\n",
       " 0.3699186991869919,\n",
       " 0.34146341463414637,\n",
       " 0.32926829268292684,\n",
       " 0.3252032520325203,\n",
       " 0.3170731707317073,\n",
       " 0.2967479674796748,\n",
       " 0.2845528455284553,\n",
       " 0.2764227642276423,\n",
       " 0.25203252032520324,\n",
       " 0.23983739837398374,\n",
       " 0.21544715447154472,\n",
       " 0.21544715447154472,\n",
       " 0.21544715447154472,\n",
       " 0.1951219512195122,\n",
       " 0.15040650406504066,\n",
       " 0.14634146341463414,\n",
       " 0.13414634146341464,\n",
       " 0.13414634146341464,\n",
       " 0.12601626016260162,\n",
       " 0.11382113821138211,\n",
       " 0.11382113821138211,\n",
       " 0.10569105691056911,\n",
       " 0.09349593495934959,\n",
       " 0.08943089430894309,\n",
       " 0.08536585365853659,\n",
       " 0.08536585365853659,\n",
       " 0.08130081300813008,\n",
       " 0.07317073170731707,\n",
       " 0.052845528455284556,\n",
       " 0.044715447154471545,\n",
       " 0.044715447154471545,\n",
       " 0.036585365853658534,\n",
       " 0.032520325203252036,\n",
       " 0.028455284552845527,\n",
       " 0.024390243902439025,\n",
       " 0.016260162601626018,\n",
       " 0.016260162601626018,\n",
       " 0.008130081300813009]"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Recall Values\n",
    "recall_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.linspace(0,1,101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting the Precision and Recall values across different thresholds\n",
    "plt.plot(thresholds[:-7],precision_values,label='Precision')\n",
    "plt.plot(thresholds[:-7],recall_values,label='Recall')\n",
    "\n",
    "plt.xlabel('Thresholds')\n",
    "plt.ylabel('Values')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "At which threshold precision and recall curves intersect?\n",
    "\n",
    "    0.2\n",
    "    0.4\n",
    "    0.6\n",
    "    0.8\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The threshold at which precision and recall curves intersect is : 0.4\n"
     ]
    }
   ],
   "source": [
    "print(\"The threshold at which precision and recall curves intersect is : %s\" % 0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Question 4\n",
    "\n",
    "Precision and recall are conflicting - when one grows, the other goes down. That's why they are often combined into the F1 score - a metrics that takes into account both\n",
    "\n",
    "This is the formula for computing F1:\n",
    "F1 = 2*((P*R)/(P+R))\n",
    "Where P is precision and R is recall.\n",
    "\n",
    "Let's compute F1 for all thresholds from 0.0 to 1.0 with increment 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate F1 Scores iterated through different thresholds\n",
    "def prec_rec_f1(y_val,y_pred):\n",
    "    thresholds = np.linspace(0,1,101)\n",
    "    f1_scores = []\n",
    "    t_f1 = []\n",
    "    \n",
    "    for t in thresholds:\n",
    "        actual_positive = (y_val ==1)\n",
    "        actual_negative = (y_val ==0)\n",
    "        \n",
    "        predict_positve = (y_pred>=t)\n",
    "        predict_negative = (y_pred<t)\n",
    "        \n",
    "        true_positive = (predict_positve & actual_positive).sum()\n",
    "        false_positive =(predict_positve & actual_negative).sum()\n",
    "        \n",
    "        true_negative = (predict_negative & actual_negative).sum()\n",
    "        false_negative = (predict_negative & actual_positive).sum()\n",
    "        \n",
    "        if (true_positive + false_positive)==0 or (true_positive+false_negative) ==0 :\n",
    "            print(\"Zero Division Error for t = %s\" % t)\n",
    "        else:\n",
    "            precision = true_positive/(true_positive + false_positive)\n",
    "            recall = true_positive/(true_positive+false_negative)\n",
    "            \n",
    "            F1 = 2*((precision*recall)/(precision+recall))\n",
    "            \n",
    "            f1_scores.append(F1)\n",
    "            t_f1.append((t,F1))\n",
    "            \n",
    "    return f1_scores,t_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero Division Error for t = 0.9400000000000001\n",
      "Zero Division Error for t = 0.9500000000000001\n",
      "Zero Division Error for t = 0.96\n",
      "Zero Division Error for t = 0.97\n",
      "Zero Division Error for t = 0.98\n",
      "Zero Division Error for t = 0.99\n",
      "Zero Division Error for t = 1.0\n"
     ]
    }
   ],
   "source": [
    "#The F1 Scores are gathered as input from the function prec_rec_f1()\n",
    "f1_scores,t_f1 = prec_rec_f1(y_val,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.01, 0.4365572315882875)"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_f1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.43271767810026385,\n",
       " 0.4365572315882875,\n",
       " 0.442429737080689,\n",
       " 0.4477335800185014,\n",
       " 0.46051379638439577,\n",
       " 0.46317829457364346,\n",
       " 0.47279920870425324,\n",
       " 0.4812942366026289,\n",
       " 0.4917355371900827,\n",
       " 0.5015873015873017,\n",
       " 0.5075593952483801,\n",
       " 0.5138427464008859,\n",
       " 0.5257142857142857,\n",
       " 0.5394581861012957,\n",
       " 0.5478468899521531,\n",
       " 0.562268803945746,\n",
       " 0.5652724968314322,\n",
       " 0.5699481865284974,\n",
       " 0.5778364116094987,\n",
       " 0.5879194630872484,\n",
       " 0.5906593406593407,\n",
       " 0.5952045133991537,\n",
       " 0.6054519368723099,\n",
       " 0.6072992700729927,\n",
       " 0.6107784431137725,\n",
       " 0.6137404580152672,\n",
       " 0.6108527131782946,\n",
       " 0.6117274167987321,\n",
       " 0.617124394184168,\n",
       " 0.6217105263157895,\n",
       " 0.6285714285714286,\n",
       " 0.6279863481228668,\n",
       " 0.6273830155979202,\n",
       " 0.6219081272084805,\n",
       " 0.6220614828209765,\n",
       " 0.6176470588235294,\n",
       " 0.6142322097378277,\n",
       " 0.6133333333333333,\n",
       " 0.6031128404669261,\n",
       " 0.5936254980079682,\n",
       " 0.5761316872427984,\n",
       " 0.5726315789473686,\n",
       " 0.5671641791044776,\n",
       " 0.5572354211663066,\n",
       " 0.5582417582417583,\n",
       " 0.551111111111111,\n",
       " 0.5540540540540541,\n",
       " 0.547945205479452,\n",
       " 0.5450346420323325,\n",
       " 0.5399061032863849,\n",
       " 0.5377358490566039,\n",
       " 0.5288461538461539,\n",
       " 0.5134474327628361,\n",
       " 0.5123152709359606,\n",
       " 0.505050505050505,\n",
       " 0.4948453608247423,\n",
       " 0.4776902887139108,\n",
       " 0.4516129032258065,\n",
       " 0.44141689373297005,\n",
       " 0.4371584699453552,\n",
       " 0.430939226519337,\n",
       " 0.4124293785310734,\n",
       " 0.4034582132564842,\n",
       " 0.39766081871345027,\n",
       " 0.37237237237237236,\n",
       " 0.36085626911314983,\n",
       " 0.3302180685358255,\n",
       " 0.33125,\n",
       " 0.33228840125391845,\n",
       " 0.3076923076923077,\n",
       " 0.24749163879598665,\n",
       " 0.2424242424242424,\n",
       " 0.22525597269624573,\n",
       " 0.22525597269624573,\n",
       " 0.21305841924398625,\n",
       " 0.1958041958041958,\n",
       " 0.1958041958041958,\n",
       " 0.18505338078291814,\n",
       " 0.16546762589928057,\n",
       " 0.15942028985507245,\n",
       " 0.15441176470588236,\n",
       " 0.15441176470588236,\n",
       " 0.14814814814814817,\n",
       " 0.1348314606741573,\n",
       " 0.09923664122137404,\n",
       " 0.08461538461538463,\n",
       " 0.08461538461538463,\n",
       " 0.0697674418604651,\n",
       " 0.06225680933852141,\n",
       " 0.054901960784313725,\n",
       " 0.04724409448818898,\n",
       " 0.03187250996015937,\n",
       " 0.03187250996015937,\n",
       " 0.01612903225806452]"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "At which threshold F1 is maximal?\n",
    "\n",
    "    0.1\n",
    "    0.3\n",
    "    0.5\n",
    "    0.7\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max F1 score is 0.6285714285714286 and the corresponding threshold is 0.3\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "for i in t_f1:\n",
    "    x.append(i[1])\n",
    "    \n",
    "    if len(x) == len(t_f1):\n",
    "        max_f1 = max(x)\n",
    "        \n",
    "        for j in t_f1:\n",
    "            if (j)[1] ==  max_f1:\n",
    "                print(\"The max F1 score is %s and the corresponding threshold is %s\" %(max_f1,round(((j)[0]),2)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Question 5\n",
    "\n",
    "Use the KFold class from Scikit-Learn to evaluate our model on 5 different folds:\n",
    "\n",
    "KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "    Iterate over different folds of df_full_train\n",
    "    Split the data into train and validation\n",
    "    Train the model on train with these parameters: LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
    "    Use AUC to evaluate the model on validation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KFold class is imported from sci-kit learn\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tqdm is imported\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to train the model\n",
    "def train(df_train,y_train,C):\n",
    "    dicts = df_train[categorical + numerical].to_dict(orient='records')\n",
    "\n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    X_train = dv.fit_transform(dicts)\n",
    "\n",
    "    model = LogisticRegression(solver='liblinear',C=C,max_iter=1000)\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    return dv,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to predict the model\n",
    "def predict(df_val,dv,model):\n",
    "    dicts = df_val[categorical + numerical].to_dict(orient='records')\n",
    "\n",
    "    X = dv.transform(dicts)\n",
    "\n",
    "    y_pred = model.predict_proba(X)[:,1]\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_splits=1 0.826 +- 0.000\n",
      "n_splits=2 0.826 +- 0.000\n",
      "n_splits=3 0.813 +- 0.017\n",
      "n_splits=4 0.816 +- 0.016\n",
      "n_splits=5 0.814 +- 0.015\n"
     ]
    }
   ],
   "source": [
    "#Function to train the model and evaluate AUC in the validation set using KFold - n_splits set to 5\n",
    "n_splits = 5\n",
    "\n",
    "kfold = KFold(n_splits=n_splits, shuffle=True, random_state=1)\n",
    "\n",
    "Auc_Scores = []\n",
    "n_split = 0\n",
    "\n",
    "for train_idx, val_idx in kfold.split(df_full_train):\n",
    "    df_train = df_full_train.iloc[train_idx]\n",
    "    df_val = df_full_train.iloc[val_idx]\n",
    "\n",
    "    y_train = df_train.default.values\n",
    "    y_val = df_val.default.values\n",
    "\n",
    "    dv, model = train(df_train, y_train, C=1.0)\n",
    "    y_pred = predict(df_val, dv, model)\n",
    "\n",
    "    Auc_Score = roc_auc_score(y_val, y_pred)\n",
    "    Auc_Scores.append(Auc_Score)\n",
    "    n_split = n_split + 1\n",
    "    \n",
    "    print('n_splits=%s %.3f +- %.3f' % (n_split, np.mean(Auc_Scores), np.std(Auc_Scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "How large is standard devidation of the scores across different folds?\n",
    "\n",
    "    0.001\n",
    "    0.014\n",
    "    0.09\n",
    "    0.14\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard devidation of the scores across different folds : 0.015\n"
     ]
    }
   ],
   "source": [
    "print(\"Standard devidation of the scores across different folds : %s\" % round(np.std(Auc_Scores),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Question 6\n",
    "\n",
    "Now let's use 5-Fold cross-validation to find the best parameter C\n",
    "\n",
    "    Iterate over the following C values: [0.01, 0.1, 1, 10]\n",
    "    Use these parametes for the model: LogisticRegression(solver='liblinear', C=C, max_iter=1000)\n",
    "    Compute the mean score as well as the std\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95c3e481b51f4535b479610ba0c32f7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter C=0.01 Mean of Auc scores = 0.808 +- 0.012\n",
      "Parameter C=0.1 Mean of Auc scores = 0.813 +- 0.014\n",
      "Parameter C=1 Mean of Auc scores = 0.814 +- 0.015\n",
      "Parameter C=10 Mean of Auc scores = 0.814 +- 0.015\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Function to train the model and evaluate AUC in the validation set using KFold - n_splits set to 5 iterated through different C parameters\n",
    "n_splits = 5\n",
    "\n",
    "for C in tqdm([0.01, 0.1, 1, 10]):\n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=1)\n",
    "\n",
    "    Auc_Scores = []\n",
    "\n",
    "    for train_index, val_index in kfold.split(df_full_train):\n",
    "        df_train = df_full_train.iloc[train_index]\n",
    "        df_val = df_full_train.iloc[val_index]\n",
    "\n",
    "        y_train = df_train.default.values\n",
    "        y_val = df_val.default.values\n",
    "\n",
    "        dv, model = train(df_train, y_train, C=C)\n",
    "        y_pred = predict(df_val, dv, model)\n",
    "\n",
    "        Auc_Score = roc_auc_score(y_val, y_pred)\n",
    "        Auc_Scores.append(Auc_Score)\n",
    "\n",
    "    print('Parameter C=%s Mean of Auc scores = %.3f +- %.3f' % (C, np.mean(Auc_Scores), np.std(Auc_Scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Which C leads to the best mean score?\n",
    "\n",
    "    0.01\n",
    "    0.1\n",
    "    1\n",
    "    10\n",
    "\n",
    "If you have ties, select the score with the lowest std. If you still have ties, select the smallest C\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2637c72b9413389749340da249e0df9e4c76d36edefe48c34c238724d995cb1b"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
